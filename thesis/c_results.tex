\chapter{Results} \label{chapter:results}

% overview of runs
% explanation of the dashboard view
% dashboard results
% resultant mesh results

For each experimental run, a dashboard view was created that can be shown for
each iteration of the simulation. The dashboard view combines several different
views of information useful for understanding the inner workings of the MABDI
algorithm. As an example, Figure \ref{fig:run1} of the next section shows the
dashboard view for the first experimental run. For these experiments, all
dashboard views follow the same pattern as described below:

\begin{itemize}
  \item (a) - Shows the global mesh $M$ from a third-person point of view and in
  the context of the simulated environment. The multi-colored mesh is $M$. The
  mesh is multi-colored in order to show the passage of time. For example, in
  Run1, The mesh is colored yellow, light green, and dark green for iterations
  1, 2, and 3 respectively. Additional items in the view show elements of the
  simulated environment: the wire frame corresponds to the viewing frustum of
  the sensor, the light blue helical line is the path of the sensor, and the
  translucent gray mesh is the simulated environment.
  \item (b) - Same as (a) except it shows the novel surface $S$ instead of
  the global mesh $M$.
  \item (c) - Plot showing the number of elements in the global mesh $M$
  after this iteration.
  \item (d \& e) - Actual $D$ and expected $E$ depth image
  respectively.
  \item (f) - The classified depth image. Points that will be used to generate
  the novel surface $S$ are shown in black. Points to be thrown away are shown
  in white.
\end{itemize}

The dashboard views are an excellent way to visualize important aspects of
MABDI. In the next section we will utilize key dashboard views to look at the
behavior and performance of MABDI during each experimental run.

\section{MABDI Performance During Experiments}

\subsection{Experiment 1}

Figure \ref{fig:run1} shows the dashboard view of the first experiment during
the third iteration. Note that \ref{fig:run1}(a) shows $M$ after the third
iteration. As stated before, $M$ is multi-colored in order to show the passage
of time. The mesh is colored yellow, light green, and dark green for iterations
1, 2, and 3 respectively. \emph{During iteration 3, $M$ is composed of only the
yellow and light green parts.}

\begin{figure}[h]%[thpb]
\centering
  \includegraphics[width=\textwidth]{figures/diagram_run1.pdf}
  \caption{Dashboard view of the first experimental run.}
  \label{fig:run1}
\end{figure}

Examining Figure \ref{fig:run1} demonstrates how the novel surface
$S$ is appended to the global mesh $M$ after each iteration of MABDI. Let's use
the figure to follow the process. It will be useful to refer to Figure
\ref{fig:system} for this section.

\begin{sloppypar} % to get rid of weird black box thing
\begin{enumerate}
  \item Input - \ref{fig:run1}(d) shows the depth image $D$ generated from the
  simulated sensor. \ref{fig:run1}(a) shows us two important aspects to consider
  about $D$. First, the pose $P$ of the sensor is shown by looking at the
  sensor's view frustum, indicated by the blue wireframe. Second, the only
  environmental information used to generate the depth image is shown in light
  gray.
  \item Generate Expected Depth Image ($E$) - \ref{fig:run1}(e) shows the
  expected depth image $E$. \ref{fig:run1}(a) also shows us two important
  aspects to consider about $E$. First, the same pose $P$ is used to create both
  $D$ and $E$ (as indicated by the blue wire frame). Second, the only
  environmental information used to create $E$ is the yellow and light green
  parts of $M$ because that is the only information $M$ contains \emph{during}
  iteration 3.
  \item Classify Depth Image ($D$) - \ref{fig:run1}(f) visualizes the
  classification process. More specifically, it shows the points as expressed in
  Equation \ref{eqn:throwaway} in white ($D_{throwaway}$). \ref{fig:run1}(f) is
  important for understanding how MABDI works because it clearly shows which
  points will be thrown away (white) and which points will be kept for
  generating the novel surface $S$ (black).
  \item Surface Reconstruction - \ref{fig:run1}(b) shows the novel surface $S$
  in the context of the simulated environment. $S$ is constructed using all the
  points colored black in \ref{fig:run1}(f).
  \item Add Novel Surface ($S$) to Global Mesh($M$) - \ref{fig:run1}(a) shows
  the novel surface $S$ appended to the global mesh $M$ in dark green.
\end{enumerate}
\end{sloppypar}

\subsection{Experiment 2}

The second experiment gives us a clear example of how the classification process
is able to identify points from the depth image $D$ that correspond to parts of
the environment that have not been seen before. In this example the global mesh
$M$ has a partial representation of the objects in the environment and when the
sensor is moved to the next pose $P$, the new perspective reveals a portion of
the object that has not been seen before. This \emph{novel portion} of the
environment, which we will be referring to, is shown by the red circle in Figure
\ref{fig:run2_novel_portion}.

\begin{figure}[h]%[thpb]
\centering
  \includegraphics[width=0.8\textwidth]{figures/run2_novel_portion.png}
  \caption{\emph{Novel portion} of the environment that we will be referring to
  in this section.}
  \label{fig:run2_novel_portion}
\end{figure}

Figure \ref{fig:run2} shows the dashboard view of the second experiment during
the second iteration. Using the dashboard view, we can follow how MABDI handles
the novel portion of the object step-by-step:
\begin{enumerate}
  \item \ref{fig:run2}(a) shows the global mesh $M$. The yellow portion of the
  mesh constitutes the entirety of $M$ after the first iteration. We can see the
  novel portion of the environment was not represented in $M$ after the first
  iteration due to occlusion.
  \item \ref{fig:run2}(d) shows the depth image $D$ from the new sensor pose
  $P$. We can see the novel portion can be seen by the sensor on this iteration.
  \item \ref{fig:run2}(e) shows the expected depth image $E$. During the second
  iteration $M$ consists of only the yellow portion shown in \ref{fig:run2}(a)
  consequently, $E$ does not show any points in the area corresponding to the
  novel portion of the environment.
  \item \ref{fig:run2}(f) shows the classification process successfully
  identifying points in $D$ that correspond to the novel portion as indeed
  novel. In the figure the points are highlighted by a red circle.
  \item \ref{fig:run2}(b) shows the novel surface $S$ now represents the novel
  portion of the environment.
  \item Finally, the orange mesh in \ref{fig:run2}(a) shows the novel portion of
  the environment is now represented by the global mesh $M$.
\end{enumerate}

\begin{figure}[h]%[thpb]
\centering
  \includegraphics[width=\textwidth]{figures/diagram_run2.pdf}
  \caption{Dashboard view of the second experimental run.}
  \label{fig:run2}
\end{figure}

\subsection{Experiment 3}

Experiment three shows how MABDI reacts to object addition. Figure
\ref{fig:run3} shows the dashboard view of the third experiment during the
twenty-sixth iteration. At this iteration the middle bunny is suddenly added to
the simulated environment. We can use the dashboard view to see the behavior of
MABDI to this new object:
\begin{enumerate}
  \item In \ref{fig:run3}(d) we see the depth image $D$ shows the new bunny.
  \item In \ref{fig:run3}(e) the expected depth image $E$ does not show the new
  bunny because $M$ has no representation of the new bunny.
  \item \ref{fig:run3}(f) shows the classification process successfully
  identified the points corresponding to the new bunny as novel.
  \item The novel points are used to generate the novel surface $S$ and then $S$
  is appended to $M$, shown in \ref{fig:run3}(a \& b).
  \item The addition of the new object resulted in a $S$ with a large number of
  elements for this particular iteration. \ref{fig:run3}(f) plots the resulting
  jump in the number of elements contained with $M$.
\end{enumerate}

\begin{figure}[h]%[thpb]
\centering
  \includegraphics[width=\textwidth]{figures/diagram_run3.pdf}
  \caption{Dashboard view of the third experimental run.}
  \label{fig:run3}
\end{figure}

\section{Global Mesh Results}

% global mesh
% elaborate
Fig \ref{fig:gm} shows the resultant global mesh $M$ from all of the experiments along with
a plot of the number of elements in the mesh over iterations. These plots show
the main contribution of MABDI because they level-off as the environment becomes
more known as opposed to traditional reconstruction methods where the number of
elements increases linearly over time.

\begin{figure}[h]%[thpb]
\centering
  \includegraphics[width=\textwidth]{figures/diagram_run123_gm.png}
  \caption{Global mesh results. Top: Run1. Middle: Run2. Bottom: Run3}
  \label{fig:gm}
\end{figure}
