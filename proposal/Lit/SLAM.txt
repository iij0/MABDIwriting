Robust Tracking for Real-Time Dense RGB-D Mapping with Kintinuous (2012 - written for ICRA 2013) t
 National University of Ireland Maynooth, MIT - Thomas Whelan, Hordur Johannsson, Michael Kaess, John Leonard, John McDonald
- First to have real-time surface coloring in their mesh representation 
- Real contribution was an very good comparison between existing state-of-the-art pose estimation algorithms
- Made some of the pose-estimation methods GPU ready and were able to obtain real-time frame rates for all
- Granted they had a beast computer... their results are very impressive and consist of many videos available online
- They don't even mention the triangulation methodology they used in order to generate the mesh. Should be the same as their last paper.
- One of their goals for future works. "updating areas of the map we are returning to that have exited the TSDF volume"
- Their goal is exactly what I want to do. This is probably the strongest argument for my case.

Kintinuous: Spatially Extended KinectFusion (Whelan et al. 2012) t
 National of Ireland Maynooth - Thomas Whelan, John McDonald
 MIT - Michael Kaess, Maurice Fallon, Hordur Johannsson, John Leonard 
- Brought up limitations of the KinectFusion algorithm which are due to the voxel representation 
- Uses the opensource implementation of the KinectFusion algorithm (KinFu)
- Allows the TSDF representation to move relative to the environment
- Uses a clever indexing to avoid translating all voxels 
- Their software is well designed with work spread across the GPU and CPU efficiently 
- When a portion of the TSDF leaves the window they turn it into a mesh and save it. 
- There is no mechanism to adapt the mesh to new data. They cite this need as future work
- Uses the mesh algorithm in "On fast surface reconstruction methods for large and noisy point clouds"
- "In the future we will extend the system to implement a full SLAM approach including loop closure detection, mesh reintegration, and global pose and mesh optimisation" 

Incremental probabilistic geometry estimation for robot scene understanding (Cashier et al. 2012) t
 University of Kyoto; Japan - Louis-Kenzo Cashier, Tetsuya Ogata, Hiroshi Okuno
- See continued works for list of 3 other extremely related works. Can't even tell where the others are from. This is from ICRA!
- "In this paper we attempt to incrementally build and maintain a polygonal mesh with embedded probabilistic spatial uncertainty"
- "To this effect, we introduce an augmented mesh structure we call a Probabilistic Polygonal Mesh (PPM), consisting of a mesh and vertex of which is associated with a measure of probabilistic certainty."
- Their algorithm consists of 4 major steps:
- 1. Ray cast through every pixel to determine which pixels intersect with current mesh and which don't
- 2. Create new mesh with all non-intersecting pixels by defining connectivity in depth map
- 3. Find vertex closest to each ray intersection. Compute the innovation vector (measure of difference) along the normal. 
- 4. Adjust the vertex by translating along the innovation vector 
- Their work is implemented in ROS C++ and is freely available on a Mercurial repository 
- Experimentations use a sensor looking at a wall. They have one figure with real world data

Efficient scene simulation for robust monte carlo localization using an RGB-D camera (Fallon et al. 2012) t
 MIT - Maurice Fallon, Hordur Johannsson, John Leonard
- Performs localization at extremely fast rates (see video) use a particle based SLAM and given map
- The map consists of large planar segments. They describe how to extract the large planar segments of the environment using a region growing technique. The end result are very large polygons representing the environment 
- Each particle simulates it's view given the map and calculates a likelihood by using the actual observation and the simulation. For this they use a simplistic sensor model of the Kinect
- Implementation uses the z-buffer of OpenGL 

An evaluation of the RGB-D SLAM system (Endres et al. 2012) t
 University of Freiburg - Felix Endres, Jurgen Hess, Nikolas Engelhard, Wolfram Burgard
 Technical University of Munich - Jurgen Sturm, Daniel Cremers
- Use RANSAC with sparse features from the point cloud which are obtained from visual features
- They test their methodology on a publicly available data set
- Their methodology is available online on ROS as "rgbdslam"

Moving volume KinectFusion (Roth and Vona 2012) t
 Northeastern University, Boston - Henry Roth, Marsette Vona
- Nothing was done real-time
- Based on the open source kinfu implementation
- The only benefit of their method over Kintinuous is that they allow the volume to rotate and translate. Not sure if that is a real benefit 
- Kept the original TSDF representation 

Adaptive RGB-D Localization (Paton and Kosecka 2012) t
 George Mason University - Michael Paton, Jana Kosecka
- The goal is to provide a more robust pose estimation which "computes the pose estimate from the most reliable measurements in a given environment" 
- They switch between ICP and estimation based on visual features. The switching is controlled by the number and quality of visual features. 

Robust Real-Time Registration of RGB-D Images using Multi-Resolution Surfel Representations (Stückler et al. 2012) t
Model Learning and Real-Time Tracking Using Multi-Resolution Surfel Maps (2012) t
Integrating depth and color cues for dense multi-resolution scene mapping using RGB-D Cameras (2012) t
 University of Bonn, Germany - Jorg Stuckler, Sven Behnka
- All three are very similar work with minor differences. For my needs, it is a closed-loop registration technique using surfels. The surfels can also adapt to new information 
- Evaluated their method using the Freiburg data set. They also created their own and made it freely available 
- Use a multi-resolution (octree) surfel representation 
- Their registration is closed-loop technique because it creates correspondences between their surfels and uses this for pose calculation 
- They claim to have a way to learn object models from the sensor data. I don't see it
- They also use a crude sensor model of the kinect. Just the squared distance
- Main concern is the scan registration 
- "Our approach utilizes multiple resolutions to align the views on coarse scales and to register them accurately on fine resolutions."
- "We proposed a novel approach to SLAM with RGB-D cameras in indoor environments. In our method, we compress the image content efficiently in 3D Multi-Resolution Surfel Maps. This map representation is well suited for accurate real-time registration by directly matching surfels and optimizing their matching likelihood."
- It does adaptively update the representation when given new information. Surfels are great for that
- They evaluate their method with the freiburg desk data set with a speed of 10Hz

DTAM: Dense Tracking and Mapping in Real-Time (Newcombe et al. 2011) t 
 Imperial College London, UK - Richard Newcombe, Steven Lovegrove, Andrew Davison
- They have a very impressive youtube video "DTAM: Dense Tracking and Mapping in Real-Time"
- "As a hand-held camera browses a scene interactively, a texture-mapped scene model with millions of vertices is generated. This model is composed of depth maps built from bundles of frames by dense and sub-pixel accurate multi-view stereo reconstruction."
- Dense methods are used for the tracking and map building part
- Pose estimation is done by comparing current images to a global model. Newcombe really seems to have a thing for this
- Performs a voxelized spatial subdivision (again a Newcombe thing) so this shouldn't be very memory efficient. And like is shown in the youtube video they are restricted to small environments 
- Driven by Augmented Reality Applications 
- Their representation is called a photometric cost volume sorta related to a TSDF

Real-time dense RGB-D localisation and mapping (2011) t
- Kintinuous refereed to "Real-time dense appearance-based SLAM for RGB-D sensors (2011) t" with this title 

Real-time dense appearance-based SLAM for RGB-D sensors (Audras and Comport 2011) t
 University of Nice Sophia-Antipolis, France - Cédric Audras, Andrew Comport
 INRIA - Maxime Meilland, Patrick Rives
- Referenced by Kintinuous for their keyframe style colored point clouds, meaning methodology to have real-time color fusion - not sure why... this paper doesn't even seem to have a used representation however their youtube video (of a slightly different name) seems to show a colored point cloud - Whelan (Kintinuous) claim they are "keyframe style colored point clouds"
- They have a youtube video "Real-time appearance-based SLAM for RGB-D sensor"
- Pose estimation driven work. Method used is image warping

Registration of 3d point clouds for urban robot mapping (2011)
 Institute of Robotics and Information (IRI), Spain
- A large technical report on minor alterations to PCL for large-scale outdoor environmental mapping

Tracking a Depth Camera: Parameter Exploration for Fast ICP (Pomerleau et al. 2011) t
 ETH Zurich - Fancois Pomerleau, Stephane Magnenat, Francis Colas, Ming Liu, and Roland Siegwart
- Due to the large number of available ICP algorithms it has become difficult to select the correct algorithms and parameters. 
- They propose a state-of-the-art modular and efficient implementation of an ICP library
- Their source code is openly available. The full code is on github. Also a version of the available combinations is available on ROS as “modular cloud matcher”
- They were able to compare many variations of the ICP algorithm and had very useful results
- They found that tracking is easier in cluttered environments. 

MAV visual SLAM with plane constraint (Lee et al. 2011) t
- Monocular camera facing down on a MAV. 
- Uses the assumption that the MAV is flying over a flat floor and imposes this assumption onto the measurements 
- Not extremely related just an example of SLAM on a MAV

Realtime Visual and Point Cloud SLAM (Fioraio and Konolige 2011) t
 Willow Garage - Nicola Fioraio, Kurt Konolige
- Good open source ROS ICP implementation which claims to be able to deal with noisy data

Real-time 3D visual SLAM with a hand-held RGB-D camera (Engelhard et al. 2011) t
 University of Freiburg Germany - Autonomous Intelligent Systems Lab - Nikolas Engelhard; Felix Endres; Jürgen Hess; Wolfram Burgard
 Technical University of Munich, Germany - Computer Vision and Pattern Recognition Group - Jürgen Sturm
- Consists of 4 processing steps
 - First extract SIFT features from the incoming depth images
 - Second estimate the relative transformation between frames using RANSAC
 - Third improve the initial estimate with a variant of the ICP algorithm
 - Perform loop closure; create Point-Cloud Maps; then create Surfel Maps
- The output of their algorithm is “a globally consistent 3D model of the perceived environment, represented as a colored point cloud”
- The full source is available on ROS as “RGBD-6D-SLAM” 

Real-time visual odometry from dense RGB-D images (Steinbrücker et al. 2011) t
 Technical University of Munich, Germany - Frank Steinbrucker, Jurgen Sturm, Daniel Cremers
- Pose estimation driven work. Method used is image warping - as said by Whelan of Kintinuous 
- They use the freiburg desk data sets for evaluation 
- "We introduced an energy-based approach to estimate the rigid body motion of a handheld RGB-D camera for a static scene."
- This work is referenced by the Kintinuous people 
- Energy-based approach to estimate the rigid body motion of a handheld RGB-D camera for a static scene
- "The key idea is to represent the rigid body motion in terms of its Lie algebra of twists and to determine the twist which maximizes the photoconsistency of the warped images."
- I am pretty sure the energy function takes into account visual and depth information
- They compared to ICP and got improvement only for small frame to frame movement 
- Their method is also faster than ICP by "two orders of magnitude." Their implementation of ICP took 8 seconds frame to frame. Not reasonable  

Visual Odometry and Mapping for Autonomous Flight Using an RGB-D Camera -- pretty much the same as “Visual Navigation for Micro Air Vehicles” meaning same people same content (Huang et al. 2011) t
 MIT, Computer Science and Artificial Intelligence Laboratory - Albert S. Huang, Abraham Bachrach, and Nicholas Ray
 University of Washington, Department of Computer Science and Engineering - Peter Henry, Michael Krainin, 
 Pontificia Universidad Catolica de Chile, Santiago, Chile - Daniel Maturana 
- Gives a good literature review of visual odometry 
- Also describes how visual odometry has been integrated with SLAM algorithms which employ loop closing techniques to detect when a vehicle revisits previous locations.
- “The problem we address is that of a quadrotor helicopter navigating in an unknown environment. The quadrotor must use the onboard RGB-D sensor to estimate its own position (local estimation), build a dense 3D model of the environment (global simultaneous localization and mapping) and use this model to plan trajectories through the environment.”
- Their approach still uses visual features to estimate the motion from frame-to-frame
- “They construct a log-likelihood occupancy grid map. They also refer to it as a voxel map In contrast, in environments with richer visual features, we have observed mean velocity errors of 0.08 m/s, with no gross failures, significantly lower than the values reported in table 1”  --  meaning their method fails in environments with poor visual features

Fast Registration Based on Noisy Planes With Unknown Correspondences for 3-D Mapping (Pathak et al. 2010) t - see cont. work

RGB-D Mapping: Using depth cameras for dense 3d modeling of indoor environments (Henry et al. 2010) t
 University of Washington, Seattle - Department of Computer Science & Engineering - Peter Henry; Michael Drainin; Evan Herbst; Dieter Fox
 Intel Labs Seattle, WA - Xiaofeng Ren; Dieter Fox
- Their global map is created using small planar colored surface patches called surfels 
- “Our algorithm uses rich visual features along with RANSAC verification to add fixed data associations into the ICP optimization. Additionally, the RANSAC associations act as an initialization for ICP, which is a local optimizer”
- Consists of 4 processing steps
 - First extract SURF features from the incoming depth images
 - Second estimate the relative transformation between frames using RANSAC
 - Third improve the initial estimate with a variant of the ICP algorithm
 - Optimize the resulting pose graph using HOGMAN
- Loop Closure Problem
 - First, loop closure detection is needed to recognize when the camera has returned to a previously visited spot
 - Second, the map must be be corrected 
 - They represent the constraints between frames with a graph structure. With edges between frames corresponding to geometric constraints. 
 - Loop closures are represented as constraints between frames that are not temporally adjacent 
 - To keep the graph sparse the define keyframes which are a subset of the aligned frames. They determine keyframes based on visual overlap. Adapting the density of keyframes to camera motion and local appearance. 
 - After they align a frame F the reuse SIFT features to find a rigid transformation with the most recent keyframe (using the RANSAC procedure)
 - As long as the number of RANSAC inliers is above a threshold they do not need to add F as a keyframe
 - The first frame which has fewer than the threshold becomes the next keyframe
 - Every time a new keyframe is created they attempt to detect a loop closure with the previous keyframes
 - Developed an new ICP variant named RGBD-ICP. Kintinuous references them for this
 
Scale drift-aware large scale monocular slam (Strasdat et al. 2010) t
 Imperial College London, UK - Hauke Strasdat, J.M.M. Montiel, Andrew Davison
- A very highly cited work and seems to be the state-of-the-art for dense visual SlAM with a monocular camera 
- This largest difficulty in this field of study is the scale estimation problem which is referenced in most every paper. Thankfully, this is not my area of study but this paper does give a summation of the best scale estimation methodologies 
- They solve the problem of scale drift during loop closure
- Representation is a point cloud 

A system for reconstruction from point clouds in 3D: Simplification and mesh representation (Alboul and Chilveros 2010) t Mesh.txt

Automatic construction of polygonal maps from point cloud data (Wiemann et al. 2010) t Mesh.txt

Real-time dense geometry from a handheld camera (Stühmer et al. 2010) t
 TU Munchen and TU Dresden, Germany - Jan Stuhmer, Stefan Gumhold, Daniel Cremers
- Here the pose estimation problem is considered to be solved
- They estimate depth maps given the pose and data from several images in real-time

Fast Registration Based on Noisy Planes With Unknown Correspondences for 3-D Mapping (Pathak et al. 2010) t

Appearance-only SLAM at large scale with FAB-MAP 2.0 (Cummins and Newman 2010) t
 University of Oxford, UK - Mark Cummins and Paul Newman 
- Highly cited work for appearance based SLAM

Live dense reconstruction with a single moving camera (Newcombe and Davidson 2010) t
 Imperial College London, UK - Richard Newcombe, Andrew Davison
- Highly cited work for dense reconstruction using a single camera. The end representation is a group of depth images and a mesh
- The mesh is adaptive to new information
- they have a very good youtube video "Live Dense Reconstruction with a Single Moving Camera"
- Claims the methods of dense reconstruction which is surveyed in "A comparison and evaluation of multi-view stereo reconstruction algorithms (2006) t (Mesh.txt)" have been previously unavailable to real-time applications due to computational costs and other restrictions  
- Like other works which estimate a set of depth images. The depth images are then fused into a mesh representation using the highly cited method "Real-Time Visibility-Based Fusion of Depth Maps (2007) t"
- "The key to dense reconstruction is precise dense correspondence between images offering sufficient baseline for triangulation, and the main novelty of our approach is the manner in which this is enabled." - this method is reliant on visual features 
- "As new points are added to the point map, a continuously updated implicit surface base model is computed and polygonised to provide a dense but approximate estimate of the scene’s surfaces (2(b))." - meaning spatial subdivision so limited to small environments 
- Vertex positions are updated using all other view around a reference frame. The vertex can move along the normal of the reference frame and the movement is defined by a linear calculation which tries to maintain the photo-consistency of the frames surrounding the reference frame
- They create several mesh surface reconstructions (one for each camera bundle) they simply stich these together because their meshes are of such good quality
- "These methods can be broadly split into two categories. Those in the first class make of use of the computed depth maps, dense oriented point samples, or volumetric signed distance functions computed from the depth maps to fit a globally consistent function that is then polygonised. This class of algorithm includes optimal approaches [2, 20], though is less amenable to larger scale reconstructions due to prohibitively large memory requirements for the volumetric representation of the global functions."
- [2] - A volumetric method for building complex models from range images (Curless and Levoy 1996) t Mesh.txt 
- [20] - A globally optimal algorithm for robust TV-L1 range image integration (Zach et al. 2007) t Mesh.txt  
- "The second class of algorithms work directly on the partial mesh reconstructions. One of the earliest methods, zippered polygon meshes [12], obtained a consistent mesh topology by removing overlapping regions to form meshes that are connected at the new boundaries"
- [12] - Zippered polygon meshes from range images (1994) t (Mesh.txt)
- "[6] have demonstrated real time fusion of noisy depth maps to obtain a set of depth maps with reduced errors and free space violations that are then polygonised."
- [6] - Real-Time Visibility-Based Fusion of Depth Maps (2007) t (Mesh.txt)
- References "A multi-scale approach to 3D scattered data interpolation with compactly supported basis functions (Ohtake et al. 2003) t Mesh.txt" as the method for generating an implicit function from their input sparse point cloud

Revisiting uncertainty analysis for optimum planes extracted from 3D range sensor point-clouds (Pathak et al. 2009) - see cont. work

Uncertainty analysis for optimum plane extraction from noisy 3D range-sensor point-clouds (Pathak et al. 2009) - see cont. work

Three-dimensional mapping with time-of-flight cameras (May et al. 2009) t
 Fraunhofer IAIS - Stefan May, David Droeschel, and Dirk Holz
 Institute of Robotics and Mechatronics, Germany - Stefan Fuchs
 INRIA - Ezio Malis
 Jacobs University - Andreas Nuchter
 University of Osnabruck - Joachim Hertzberg
- Highly cited work for SLAM from ToF cameras 
- Create an ICP method made for ToF cameras. That can handle large translations and small FOV
- Representation is a point cloud. The contribution of their work is how to deal with problems of ToF sensors

Navigating, recognizing, and describing urban spaces with vision and laser (Newman et al. 2009) t
 University of Oxford - Paul Newman, Gabe Sibley, Mike Smith, Mark Cummins, Alastair Harrison, Chris Mei, Ingmar Posner, Robbie Shade, Derik Schroeter, Liz Murphy, Winston Churchill, Dave Cole, Ian Reid
- Sensor: Stereo Camera and LIDAR; Segway RMP platform
- "We show how our choices of representation, inference mthods and use of both topological and metric techniques naturally allow us to fuse maps built from multiple sessions with no need for manual frame alignment or data association."
- Their local pose and trajectory estimation: "...is driven by robust inter-frame feature tracking across sequential stereo image pairs." They use a sliding window filter to marginalize out older measurements 
- Topology inference - Loop closure is performed by following the work of Cummins and Newman 2007, 2008a, 2008b. "is probabilistic and solely appearance based" Uses bag of words features
- Global optimization - "The pose estimation system directly provides high-quality interpose constraints. The metric parameterization of the loop closures are however very uncertain: all we know is that we are close to a place we have been before." Basically, if the topology inference finds a loop then ICP is used on "local-region" point clouds which come from either the laser scanner or the stereo rig. The then perform pose relaxiation over the graph of poses 
- The LIDAR isn't used for pose estimation they claim. The laser information is added to the map by noting when and where the data was taken. 
- The depth information for their stereo rig is even added to the model ".. but here it is used to fill in the 3D structure of the workspace which is not sampled by our laser scanners, thus producing total scene coverage."
- Semantic labeling - They use machine learning to learn a generative model of visual and geometric appearance. They can then classify region of the point clouds into one of 7 classes using a support vector machine
- They do a good job of describing their probabilistic framework for pose estimation simply and clearly
- The optimization of their pose graph (i.e. everything that isn't the pose trajectory estimation) is an off line process
- Delta: the size of their maps ~15km, semantic labeling of the map

Fast plane detection and polygonalization in noisy 3D range images (Poppinga et al. 2008) t - see cont. work
 Jacobs University - Juan Poppinga, Narunas Vaskevicius, Andreas Birk, Kaustubh Pathak
- "A fast but nevertheless accurate approach for surface extraction from noisy 3D point clouds is presented. It consists of two parts, namely a plane fitting and a polygonalization step."
- I have their source code 
- Sensor: ToF camera; Representation: Polygon mesh but doesn't seem to be adaptive to new information

Online generation of scene descriptions in urban environments (Posner et al. 2008)
- Concerned with the semantic labeling of scenes 
- Sensors used are laser scans and camera information

FrameSLAM: From bundle adjustment to real-time visual mapping (Konolige and Agrawal 2008) t
 Willow Garage - Kurt Konolige
 SRI International - Motilal Agrawal
- Highly cited work in the field of Visual SLAM. They call their method frameSLAM
- Their method uses stereo camera and the representation is a point cloud 
- "The key component is a skeleton system of visual frames that act both as landmarks for registration, and as a network of constraints for enforcing consistency"

Large-scale 6-DOF SLAM with stereo-in-hand (Paz et al. 2008) t
 Universidad de Zaragoza, Spain - Lina Paz, Pedro Piniés, Juan Tardó, José Neira
- Highly cited work in visual SLAM
- A Divide and Conquer method which allows it to be scalable because not all of the landmarks are in the estimated state at one time
- Representation is a point cloud of features 

iSAM: Incremental smoothing and mapping (Kaess et al. 2008) t 
 Massachusetts Institute of Technology - Honda Research - Georgia Institute of Technology - Michael Kaess, Ananth Ranganathan, and Frank Dellaert
- Sensor used in experimental data sets: laser range finder
- Representation: Point map
- Very robust to loop closure.
- Operates in real time for extended periods of time. However, the method becomes more computationally burdensome over time
- "To the best of our knowledge, updating of matrix factorizations has not been applied in the context of SLAM yet."

FAB-MAP: probabilistic localization and mapping in the space of appearance (Cummins and Newman 2008) t
Accelerated appearance-only SLAM (Cummins and Newman 2008) t
- Refer to newer work "Appearance-only SLAM at large scale with FAB-MAP 2.0 (Cummins and Newman 2010) t"

Detailed real-time urban 3D reconstruction from video (Pollefeys et al. 2007) t
 University of North Carolina - Work with 19 authors! Pollefeys et al.
- Prior work is "Towards urban 3D reconstruction from video (2006) Akbarzadeh et al."
- Referenced by Newcombe in "Live dense reconstruction with a single moving camera (2010) t" as a dense reconstruction method for large urban scenes. Also says this work is most similar in spirit
- Has a step named depth map fusion - "In this step, a set of depth maps from neighboring camera positions are combined into a single fused depth map for one of the views."
- "In this paper, we introduce a large-scale, 3D reconstruction system that operates at approximately 30 Hz while still delivering detailed 3D models in the form of textured polygonal meshes"
- System consists of 8 cameras mounted on a vehicle. Each camera stream is processed by 1 CPU node in order to obtain real-time performance 
- "After fusion, a polygonal model is constructed by a simple module that produces a multi-resolution triangular mesh using a simplified version of the quad-tree approach of Pajarola (2002). The same module also detects and merges overlapping surfaces between consecutive fused depthmaps and fills holes."
- Pajarola (2002) - "Fast Depth-Image Meshing and Warping (2002) t Mesh.txt"
- "Despite its simplicity, this scheme is effective when the camera maintains a dominant direction of motion. It does not handle, however, the case of a part of the scene being revisited in a later pass, since the entire reconstructed model cannot be kept in memory."
- They have a huge reference to surface reconstruction techniques 

3D plane-based egomotion for SLAM on semistructured environment (Viejo and Cazorla 2007) t
 Universidad de Alicante, Spain - Diego Viejo and Miguel Cazorla
- A plane-based ICP method for 3D SLAM applications using a laser sensor
- Representation is a point cloud

Probabilistic appearance based navigation and loop closing (Cummins and Newman 2007) t
- Refer to newer work "Appearance-only SLAM at large scale with FAB-MAP 2.0 (Cummins and Newman 2010) t"

A tree parameterization for efficiently computing maximum likelihood maps using gradient descent (Grisetti et al. 2007) t
 University of Freiburg - Giorgio Grisetti, Cyrill Stachniss, Slawomir Gronka, Wolfram Burgard
- "In this paper, we presented a highly efficient solution to the problem of learning maximum likelihood maps for mobile robots. Our technique is based on the graph-formulation of the simultaneous localization and mapping problem and applies a gradient descent based optimization scheme."

Scan registration for autonomous mining vehicles using 3D-NDT (Magnusson et al. 2007) t
 Orebro University, Sweden - Martin Magnusson, Achim Lilienthal
 University of Lincoln - Tom Duckett
- Creates a representation using a NDT which is essentially an occupancy grid using normal distributions 
- Uses spatial subdivision 

Mapping large loops with a single hand-held camera (Clemente et al. 2007) t
 Univeristy of Zaragoza, Spain - Laura Clemente, Jose Neira, Juan Tardos
 Imperial College London - Andrew Davidson
 University of Oxford - Ian Reid
- Sensor: Monocular Camera; Representation: 2D map of point features
- Good reference for Hierarchical SLAM technique. 
- Able to build large outdoor maps. Their system is based on the Hierarchical Map approach and inverse depth representation. These 2 methods had been developed by the authors prior to this publication
- "In this paper we have demonstrated large scale, loop closing, near real time SLAM with a single camera"

Parallel tracking and mapping for small AR workspaces (Klein and Murray 2007) t 
 University of Oxford - Georg Klein, David Murray
- Extremely Cited. Sensor: Single Camera; Representation: 3D map of point features
- The use a "FAST-10" corner detector to create features
- They run 2 seperate threads on a dual core machine. The first does sensor tracking and the second does map building.
- Sensor tracking is done in a feedback manner. The features from the global map are projected into the cameras frame. The initial guess for the camera's frame is initialized with a motion model called the "decaying velocity model". 
- They minimize an error function based on the reprojection error to update the pose
- Map needs to be initialized with a stereo technique. User takes a presses a button to take a snapshot. Moves and repeats. The translations is assumed to be 10cm?! How could you know?
- Keyframes are created on heuristic rules. The keyframe is then added to the map
- As the map increases so does calculation time
- "it will fail if the real-world scene is substantiall and permanently changed"
- Tracking doesn't deal well with occlusion becuase it expects the points to be there due to the type of representation. In other words, there is nothing saying that the point lies on the other side of the object. It is able to get accurate pose estimations becuase of several outlier detection schemes.
- System is not designed to close large loops

MonoSLAM: Real-time single camera SLAM (Davison et al. 2007) t
 Imperial College - Andrew J. Davison
 University of Oxford - Ian D. Reid
 The Surrey Technology Centre - Nicholas Molton
 Joint Japanese-French Robotics Laboratory - Olivier Stasse
- Sensor: Single camera, Representation: Point cloud of landmarks 
- "Our key novel contributions include an active approach to mapping and measurement, the use of a general motion model for smooth camera movement, and solutions for monocular feature initialization and feature orientation estimation."
- Mention in the conclusion that denser representations are needed

Estimation of accurate maximum likelihood maps in 3D (Grisetti et al. 2007) t
 University of Freiburg - Giorgio Grisetti, Slawomir Grzonka, Cyrill Stachniss, Patrick Pfaff, Wolfram Burgard
- Contribution is on loop closure and how to distribute a rotational error over a sequence of poses 
- Representation is landmark locations 

Real-time SLAM relocalisation (Williams et al. 2007) t
 University of Oxford - Brian Williams, Georg Klein, Ian Reid 
- Contribution is a system that can detect tracking failure and recover. Does it by maintaining a list of keypoints 
- Representation is landmark locations 

Detecting loop closure with scene sequences (Ho and Newman 2007) t
 University of Oxford - Kin Leong Ho, Paul Newman
- Contribution is a completely independent loop closure scheme 
- Similarity can be designed from visual features or laser images 

6d slam - mapping outdoor environments (Nüchter et al. 2007) t
 University of Osnabruck - Andreas Nuchter, Kai Lingemann, Joachim Hertzberg
 Franhofer Institute IAIS - Hartmut Surmann
- "This paper has presented a new solution to the simultaneous localization and mapping (SLAM) problem with six degrees of freedom. The method is based on ICP scan matching, with odometry extrapolation, initial pose estimation using a coarse-to-fine strategy with an octree representation, and closing loop detection."

Using laser range data for 3d SLAM in outdoor environments (Cole and Newman 2006) t
 University of Oxford - David Cole and Paul Newman
- "We have demonstrated that by extending existing 2D SLAM techniques, and augmenting them with a data segmentation and scan match classification stage, we can perform 3D probabilistic SLAM in outdoor terrain."
- Representation: location of landmarks 

Unified inverse depth parametrization for monocular SLAM (Montiel et al. 2006) t
 Universidad de Zaragoza - J.M.M. Montiel, Javier Civera
 Imperial College London - Andrew Davison
- see continued work below

Outdoor SLAM using visual appearance and laser ranging (Newman, Cole, and Ho 2006) t
 University of Oxford - P. Newman, D. Cole, K. Ho
- See newer work "Using laser range data for 3d SLAM in outdoor environments (Cole and Newman 2006) t"

Towards urban 3D reconstruction from video (Akbarzadeh et al. 2006) t
 University of Kentucky - University of North Carolina at Chapel Hill - A. Akbarzadeh, J. M. Frahm, P. Mordohai, B. Clipp, C. Engles, D. Gallup, P. Merrell, M. Phelps, S. Sinha, B. Talton, L. Wang, Q. Yang, H. Stewenius, R. Yang, G. Welch, H. Towles, D. Nister, M. Pollefeys
- See newer work "Detailed real-time urban 3D reconstruction from video (Pollefeys et al. 2007) t"
- Sensor: Video stream, GPS, INS. - 8 cameras mounted on a vehicle 
- Not real time. But they feel with the right hardware (GPU) and optimizations it could be. 
- They use a 10-PC computer cluster
- Fist step is sparse reconstruction to determine the poses of the cameras. It is based of work in structure from motion, and INS/GPS fusion data
- Second step is dense reconstruction which produces texturized depth maps using multi-view stereo and depth map fusion techniques 
- All technologies presented don't seem to be new. However the overall scale of their implementation is what makes it impressive. Results seem to be very good

Fast iterative optimization of pose graphs with poor initial estimates (Olson et al. 2006) t
 MIT, Artificial Intelligence Laboratory - Edwin Olson, John Leonard, Seth Teller
- Highly cited work for Graph-Based SLAM pose optimization. Representation is landmark locations 
- "We present a nonlinear map optimization algorithm which can optimize a map een when the initial estimate of the map is poor."
- "An alternative state space representation that allows a single iteration to update many poses without incurring large computational cost."
- "A variant of the Stochastic Gradient Decent algorithm that is robust against local minima and converges quickly."
- Their experimental data was a large set of laser scan data. The "Killian Court" data set. The scans were processed to provide pose estimates which created pose estimates between frames. Loop closures were found manually. 
- Their algorithm was able to determine a good map in under a second of a robot who traveled for more than 2 hours. 
- Basically, they developed a very simple and fast graph based global optimization method. The method must know where loop closures occur and have successive pose estimates.

Simultaneous localisation and mapping (SLAM): Part I the essential algorithms (Durrant-Whyte and Bailey 2006) t
 University of Sydney - Hugh Durrant-Whyte, Tim Bailey
- History of the SLAM problem
- Description of the general SLAM framework; EKF-SLAM, Rao-Blackwellized Filter
- Table of Open-source SLAM software and Online datasets

Simultaneous localisation and mapping (SLAM): Part II state of the art (Durrant-Whyte and Bailey 2006) t
 University of Sydney - Hugh Durrant-Whyte, Tim Bailey
- Computational complexity - optimal and conservative algorithms
- Sparsification and submaps 
- Data association 
- Environment representation 
- Trajectory-Oriented SLAM

3D SLAM using planar segments (Weingerten and Siegwart 2006) t
 Swiss Federal Institute of Technology - Jan Weingarten, Roland Siegwart
- Extremely related work. They make planar patches from the input data and then turn them into a mesh
- Their isn't a mechanism for adapting this mesh to new information. It seems to be a post-processing step

A multilevel relaxation algorithm for simultaneous localisation and mapping (Frese et al. 2005) t
 Bremen Institute of Safe Systems, Germany - Udo Frese
 NamaTec, Sweden - Per Larsson
 Orebro University, Sweden - Tom Duckett
- A loop closure method for 3D SLAM
- Representation: Point cloud 

Improving simultaneous mapping and localization in 3D using global constraints (Triebel and Burgard 2005)
- Plane based pose estimation

Improving gridbased SLAM with Rao-Blackwellized particle filters by adaptive proposals and selective resampling (Grisetti et al. 2005) t
- Extremely cited work on how to better do particle based SLAM
- "Recently Rao-Blackwellized particle filters have been introduced as effective means to solve the simultaneous localization and mapping (SLAM) problem. This approach uses a particle filter in which each particle carries an individual map of the environment. Accordingly, a key question is how to reduce the number of particles."
- Representation is point cloud of features

Square Root SAM (Dellaert and Kaess 2005) t
 Georgia Institute of Technology – Frank Dellaert, Michael Kaess
- Representations - point map of landmarks
- Attempt to look at applying square root filtering at the SLAM problem
- Sensor for the experimental results: 8 cameras
- Not quite real-time processing. They showed speed improvements over initial EKF methods.
- Computational complexity grows without bound over time as with initial EKF based methods. 
- This is a batch algorithm. They are trying to make it incremental 

6D SLAM with approximate data association (Nuchter et al. 2005) t
 University of Osnabruk – Fraunhofer Institute for Autonomous Intelligent Systems; Sankt Augustin, Germany – Andreas Nuchter, Kai Lingerman, Joachim Hertzberg, Hartmut Surman
- “A solution to 6D SLAM that considers all free parameters in the robot pose is built based on 3D scan matching”
- Sensor: 2D laser range scanner that is capable of panning. Generating a scan with 181x256 data points takes 3.4 seconds. Thus scanning is done in a stop and go fashion. Representation: Point cloud
- Method works by performing ICP on acquired data. They develop a method for global optimization of the matches. 
- They discuss and apply kd tree and point reduction optimizations as part of their methods.
- Their ICP matching took several seconds. However, I believe it used no estimate from odometry and had to deal with large movements

Preemptive RANSAC for live structure and motion estimation (2005)
 Princeton - David Nister
- Sensor: Single camera; Representation: Sparse point maps
- The systems operates in real time.
- Has a “preemptive” scheme for RANSAC. From what I gather basically a method to determine if hypotheses should be explored more thoroughly or dropped. 
- Basically one of the first real-time applications of robustly determining the ego motion of the sensor

Unconstrained 3D-Mesh Generation Applied to Map Building (Viejo and Cazorla 2004) t 
 Universidad de Alicante, Spain - Diego Viejo, Miguel Cazola
- Present a method for "unconstrained 3D-mesh generation from a not-uniformly distributed point cloud"
- A non real-time method. Older but very related work
- They generate a mesh by incremental element addition starting with a seed element 
- They have a method for aligning normals based on neighboring points

Towards 3d mapping in large urban environments (Howard et al. 2004) t
 University of Southern California - Andrew Howard, Denis Wolf, Gaurav Sukhatme
- “This paper describes work-in-progress aimed at generating dense 3D maps of urban environments using laser range data acquired from a moving platform.”
- Maps aim to preserve both fine detail (~centimeters) in large maps (~.5 km on a side)
- Sensors: Laser range finder and IMU; Representation: Large point cloud
- Uses a Segway RMP robot
- “Basic mapping algorithm has 4 steps”
- 1. Fine scale localization: IMU, odometry and laser range-finder data is combined to produce incremental pose estimates for the robot. (Subject to drift)
- 2. Coarse-scale localization: GPS is used to determine an approximate robot pose. If GPS is not available they also describe a method based on a modified Monte-Carlo Localization algorithm that can localize with a map generated from satellite or aerial imagery. 
- 3. Coarse-to-fine localization: Optimize the map for local continuity and global consistency. 
- 4. Generate a map. 
- They made a map with 8 million points

An efficient solution to the five-point relative pose problem (Nistér 2004) t
 Pinceton - David Nister
- Highly cited algorithm for calculating a pose given 5 corresponding points
- “The problem is to find the possible solutions for relative camera pose between two calibrated views given five corresponding points.” 
- Developed algorithm is used in conjunction with RANSAC algorithm to determine the motion of a camera in real time quite robustly. 
- Several convincing example cases were given

Visual modeling with a hand-held camera (Pollefeys 2004) t
 University of North Carolina - Marc Pollefeys
 Katholieke Universiteit Leuven, Leuven, Belgium - Luc Van Gool, Maarten Verguawen, Fraank Verbiest, Kurt Cornelis, Jan Tops
- See newer work "Detailed real-time urban 3D reconstruction from video (Pollefeys et al. 2007) t"
- Just like newer work. This is a mesh created from depth map fusion
- In this older work. It is not real-time and mesh building is a post-processing step

DP-SLAM 2.0 (Eliazar and Parr 2004) t
 Duke University - Austin Eliazar, Ronald Parr
- Sensor: Laser; Representation: Occupancy Grid
- Contribution: Computationally less expensive particle based SLAM

A system for volumetric robotic mapping of abandoned mines (Thrun et al. 2003) t
 Carnegie Mellon - University of Freiburg - Sebastian Thrun; Dir Hahnel; David Ferguson; Michael Montemerlo; Rudolph Triebel; Wolfram Burgard; Christopher Baker; Zachary Omohundro; Scott Thayer; William Whittaker
- Sensor: Multiple 2D laser range scanners
- Approach relies on planar scan matching to localize the robot. 
- Also described an offline optimization scheme to assure globally consistent map to deal with cyclic environments. 
- Looks like point cloud data

Learning compact 3D models of indoor and outdoor environments with a mobile robot (Hähnel et al. 2003) t
 University of Freiburg - Carnegie Mellon - Dirk Hahnel; Wolfram Burgard; Sebastian Thrun
- Sensor: Multiple 2D laser scans.
- One 2D laser scan is used for localisation. Essentially limiting the world to a planar environment in which points are added to create the 3D environment 
- Mesh is created by simply joining near points in the range data. 
- Larger structures (in this paper, planar surfaces) are extracted offline
- “The algorithm to find planes for sets of points is a randomized approach. It starts with a randomly chosen point in 3D and applies a region growing technique to find a maximum set of points in the neighborhood to which a fitting plane can be found.”
- This type of plane extraction algorithm is very similar to others I have read. Need to investigate that. 
- Gives a good plot of the surface normals of a supposedly flat wall. Ideally all data would agree to a very similar surface normal. However, because of the noise inherent in laser range data, the data shows surface normals which are nearly uniformly distributed. 
- Had to move the robot at slow speeds. About 10cm/s (4in/s)
- Needed 52 minutes to extract planes from a hallway data set

An autonomous mobile robot with a 3d laser range finder for 3d exploration and digitalization of indoor environments (Surmann et al. 2003) t
- Fraunhofer Institute for Autonomous Intelligent Systems - Sankt Augustin, Germany - Hartmut Surmann; Andreas Nuchter; Joachim Hertzberg
- Representation: 3D volumetric grid using octrees 
- Claim to be the first to use a 3D laser scanner
- Methods up to this point which constructed 3D models used multiple 2D scanners. One scanner to determine the pose and the others looking up at an angle to measure 3D points. 
- One of the first works to use a 3D scanner with the ICP algorithm. 
- Their 3D scanner is build by putting a 2D scanner on a servomotor
- Their scanning method determines lines and planes from the scan. A mesh is applied offline. 
- They reference "Robust meshes from multiple range maps (Pulli et al. 1997) t " as the method for building their mesh. It is a volumetric method

Real-time simultaneous localisation and mapping with a single camera (Davinson 2003) t
 University of Oxford - Andrew J. Davison
- This paper pushes the real-time part
- “We have described a principled, Bayesian, top-down approach to sequential Simultaneous Localisation and Mapping or Structure from Motion”
- Creates very sparse maps
- One of the first to not rely on odometry 

An efficient FastSLAM algorithm for generating maps of large-scale cyclic environments from raw laser range measurements (Hähnel et al. 2003) t
 University of Freiburg - Dirk Hahnel, Wolfram Burgard
 University of Washington - Dieter Fox
 Stanford University - Sebastian Thrun
- Continuation of "FastSLAM: A Factored Solution to the Simultaneous Localization and Mapping Problem (Montemerlo 2002) t"

Robotic mapping: A survey (2003)
 Carnegie Mellon - Thrun 
- Extremely well cited and large survey of the “field of robotic mapping”
- Gives a break down of the representations used up until 2003. Use this to explain the history of references 
- Explains the main problems in robotic mapping: measurement noise, high dimensionality of the problem, environments change over time, the data association problem (and how it pertains to closing the loop), and to some extent frontier exploration
- “we notice that the robot mapping problem is like a chicken and egg problem: If the robot’s pose was known all along, building a map would be quite simple. Conversely, if we already had a map of the environment, there exist computationally elegant and efficient algorithms for determining the robot's pose at any point in time. 
- “A key advantage of the EM algorithm over Kalman filtering lies in the fact that is solves the correspondence problem.”
- Discusses occupancy grid maps and object maps
- Object maps are the kind of maps used in Thrun’s own “Using em to learn 3d models of indoor environments with mobile robots.” In this work the method found data which matched a planar model. 
- “The object mapping approach in … remedies this problem by assuming that parts of the environment consists of large flat surfaces.”
- Makes a category named object maps which has methods using polygon representations. [6, 58, 61]
- [6] - Towards object mapping in dynamic environments with mobile robots (Biswass et al. 2002)
- [58] - Using EM to learn 3D models with mobile robots (Liu et al. 2001)
- [61] - Real-time acquisition of compact volumetric 3D maps with mobile robots (Martin and Thrun 2002)

Towards object mapping in dynamic environments with mobile robots (Biswas et al. 2002) t
 Stanford University - Rahul Biswas, Benson Limketkai, Scott Sanner
 Carnegie Mellon University - Sebastian Thrun
- Sensor: Laser; Representation: Occupancy Grid
- Contribution: Can model moving objects in occupancy grid representations 

Real-time acquisition of compact volumetric 3D maps with mobile robots (Martin and Thrun 2002) t
 Carnegie Mellon University - Christian Martin, Sebastian Thrun
- Sensor: Laser; Representation: Polygon mesh
- Real-time algorithm for incrementally building a mesh representation 
- Restricted to rectangular flat surfaces

FastSLAM: A Factored Solution to the Simultaneous Localization and Mapping Problem (Montemerlo 2002) t
- Carnegie Mellon University - Stanford University - Michael Montemerlo; Sebastian Thrun; Daphne Koller; Ben Wegbreit
- Extremely cited; EKF-based SLAM algorithm; Sensor: SICK laser range finder; Representation: Location of landmarks
- “However, few approaches to this problem scale up to handle the very large number of landmarks present in real environments”
- “Kalman filter-based algorithms, for example, require time quadratic in the number of landmarks to incorporate each sensor observation. … (their algorithm) scales logarithmically with the number of landmarks in the map.”
- “FastSLAM decomposes the SLAM problem into a robot localization problem, and a collection of landmark estimation problems”
- Key contribution was the ability of their method to scale well. Uses multiple particle filters. 
- “This algorithm utilizes a Rao-Blackwellized representation of the posterior, integrating particle filter and Kalman filter representations”

Robust Monte Carlo localization for mobile robots (Thrun et al. 2001)
 Carnegie Mellon - University of Washington - University of Freiburg - Sebastian Thrun; Dieter Fox; Wolfram Burgard; Frank Dellaert
- Highly referenced as state-of-the-art in Monte Carlo Localisation (MCL); Representation: Landmark locations
- “This article presents a family of probabilistic localization algorithms known as Monte Carlo Localization (MCL)”
- “Markov localization algorithms, in contrast, represent beliefs by piecewise constant functions (histograms) over the space of all possible poses.”
- “In other words, rather than approximating posteriors in parametric form, as is the case for Kalman filter and Markov localization algorithms, MCL represents the posteriors by a random collection of weighted particles, which approximates the desired distribution”

Data association in stochastic mapping using the joint compatibility test (Neira and Tardós 2001) t
 Universidad de Zaragoza; Spain - José Neira, Juan Tardós
- "In this paper, we address the problem of robust data association for simultaneous vehicle localization and map building"

A solution to the simultaneous localization and map building (SLAM) problem (Dissanayake et al. 2001) t  
 The University of Sydney, Australian Centre for Field Robotics - Gamini Dissanayake, Paul Newman, Steven Clark, Hugh Durrant-Whyte, M. Csorba
- Sensor: millimeter wave radar; Robot was a car. pretty neat; Representation: Landmark locations
- “An estimation-theoretic or Kalman filter based approach to the SLAM problem is adopted in this paper.”
- Any methods following this thought have to estimate not only the state of the robot but also the state of all landmarks in the map as part of the state estimation. They claim that up to this point it was believed to be computationally too complex. So methods employed a series of approximations to the full SLAM problem. For example, a series of decoupled vehicle to landmark filters. Such as Durrant-Whyte “Directed Sonar: Sensing for Mobile Robot Navigation”
- Provides a very rigorous Kalman Filter derivation of the SLAM problem from a classical estimation-theoretic framework. Relied heavily on the work from Smith “Estimating Uncertain Spatial Relationships in Robotics”
- Smith’s work was more than 10 years before this!
- They gave 3 Theorems describing the convergent behavior of their Kalman filter.
- Maps consisted of estimated locations of landmarks
- Delta: 3 theoretical theorems of convergence, 

Using EM to learn 3d models of indoor environments with mobile robots (Liu et al. 2001) t
 Carnegie Mellon - University Freiburg - Yufeng Liu, Rosemary Emery, Deepayan Chakrabarti, Sebastian Thrun
 Albert-Ludwigs-University Freiburg, Freiburg, Germany - Wolfram Burgard;
- Sensor: 2d laser range finders and panoramic camera
- This is planes-based work!
- “In a final post-processing step, measurements are converted into polygons and projected onto the surface model where possible”
- “The most popular paradigm in 2D mapping to date are occupancy grid maps. Occupancy grids represent environments by fine grained grids. While this is feasible in 2D, in 3D the complexity of these representations pose serious scaling limitations.”
- “Our algorithm simultaneously estimates the number of surfaces and their location. Measurements not explained by any surface are retained”
- “The result of the modeling is a low-complexity polygonal model of both structure and texture. The model is represented in VRML, a common virtual reality format. 
- The pose estimation and point map building are performed using their prior work. This work basically addresses the need to reduce the data. Meaning a post-processing step.

A real-time algorithm for mobile robot mapping with applications to multi-robot and 3D mapping (Thrun et al. 2000) t
 Carnegie Mellon; Pittsburgh, PA - Sebastian Thrun, Dieter Fox
 University of Freiburg; Germany - Wolfram Burgard
- EM based SLAM; Sensor: 2d laser range finders (LIDAR); Representation: Point cloud
- One of the first works to deal with cyclic environments (i.e. closing the loop)
- They mention that past algorithms usually do a multi-dimensional greedy search of the best change in pose given the odometry information and the current sensor readings. Once the pose is found it is locked down forever and the new information is unioned with the global map.
- “The brittleness of the approach, thus, is due to two factors: Past estimates are never revised, and only a single guess is maintained as to where the robot is, instead of a full distribution. Notice that neither of these restrictions applies to the EM family of mapping algorithms.”
- “our approach computes the full posterior over robot poses … The posterior is a probability distribution over poses conditioned on past sensor data.”
- They achieve 3d maps by having a robot with 2 laser range finders. One to localize the robot and the other looking up to obtain the rest of the picture. So to speak. 
- The created meshes by post processing the point maps. 
- Found that their method was very robust  

3-D Motion and Structure from 2-D Motion Causally Integrated over Time: Implementation (Chiuso et al. 2000) t
 Washington University - Paolo Favaro; Hailin Jin; Stefano Soatto
 Universitá di Padova, Italy - Alessandro Chiuso 
- EKF based algorithm; Sensor: single camera
- No mapping was done. Just a nonlinear filter which was used to estimate the structure and motion between frames as the states.
- Assumes that the correspondence is known between features in images.
- “The causal estimation of three-dimensional structure and motion can be posed as a nonlinear filtering problem.” 

Incremental mapping of large cyclic environments (Gutmann and Konolige 1999) t
 Institut fur Informatik - Jens-Steffen Gutmann
 SRI International - Kurt Konolige 
- Early work on the SLAM problem main contribution is loop closure
- Sensor: Laser; Representation: Landmark locations

A probabilistic approach to concurrent mapping and localization for mobile robots (Thrun et al. 1998) t
 Carnegie Mellon - Sebastian Thrun 
 Universität Bonn; Germany - Wolfram Burgard; Dieter Fox
- Sensor: Laser; Rep: Landmark locations
- Batch algorithm; so not for real-time applications. Completely offline. One map generation took 41 minutes of computation time. 
- Robot was driven by an operator who also pushed a button at significant locations (landmarks). Roughly corresponded to meet points described in (Choset, 1996 i.e. dead ends and intersections of hallways). 
- Present probability distributions used for robot motion and robot perception. Pretty classic stuff
- There were incremental approaches before this work. The delta they claim is that no other method can revise past location estimates. 

Mobile Robot Exploration and Map-Building with Continuous Localization (Yamauchi et al. 1998) t
 Navy Center for Applied Research in Artificial Intelligence - Washington, DC - Brian Yamauchi; Alan Schultz; William Adams
- Representation - 2d evidence grids. (range [-1 1] with -1 signifying not occupied)
- Sensors - Sonar and a “triangulation-based structured light range finder”
- Continuous Localization is performed based off their prior work
- They named their system ARIEL (Autonomous Robot for Integrated Exploration and Localization) 
- Combines their mapping technique with frontier-based exploration 
- Delta: One of the first to incorporate frontier exploration, claims to be better at dealing with clutter then prior methods 

Continuous Localization Using Evidence Grids (Schultz et al. 1998) t
- Navy Center for Applied Research in Artificial Intelligence - Washington, DC - Alan Schultz; William Adams
- Representation - 2d evidence grids. (range [-1 1] with -1 signifying not occupied)
- Sensors - Sonar and a “triangulation-based structured light range finder”
- “Previous techniques for localization have looked at learning and recognizing landmarks in the environment, either as geometric representations or as a representation of sensor readings.”
- “In this study, the robot does not need to rely on the presence of specific landmarks, but instead uses the entire local environment of the robot to determine its location.”
- First paper to introduce the idea of Continuous Localization CL. In fact that is what they called it.
- They claim all other techniques before it corrected errors periodically after some build up. 
- The map was given a priori. The robot builds a short term map and uses the given map to globally register itself.  
- The local map is registered to the larger map by doing a greedy search in the immediate pose space. 

A robot exploration and mapping strategy based on semantic hierarchy of spatial representations (Kuipers and Byun 1991) t
 University of Texas at Austin - Benjamin Kuipers, Yung-Tai Byun
- 2D SLAM; Sensor: Laser; Representation: Landmark locations 

Estimating Uncertain Spatial Relationships in Robotics (Smith et al. 1987) t
 General Motors Research Labs - Randall Smith
 UC Berkeley - Matthew Self
 NASA Ames Research Center - Peter Cheeseman
- Extremely highly cited work on the start of EKF based SLAM
- “In this paper, we describe a representation for spatial information, called the stochastic map, and associated procedures for building it, reading information from it, and revising it incrementally as new information is obtained.”
- “The map contains the estimates of relationships among objects in the map, and their uncertainties, given all the available information.” 
- Experiments were done in simulation.
- Really just a first crack at defining the problem framework from basic principles. 


__________________________________________________________________________ Continued Works 

Incremental Probabilistic Geometry Estimation for Robot Scene Understanding (Cashier et al. 2012) t
Fast Incremental Probabilistic Surface Reconstruction for Robot Scene Understanding (Cashier et al. ~)
Time-of-flight camera based probabilistic polygonal mesh mapping (Cashier 2011 et al.)
Probabilistic polygonal mesh for 3D SLAM (Cashier et al ~)
- Prior three works are very difficult to find.. even the year
- Last one is extremely related 

Fast Plane Detection and Polygonalization in Noisy 3D Range Images (Poppinga et al. 2008) t
Fast Registration Based on Noisy Planes With Unknown Correspondences for 3-D Mapping (Pathak et al. 2010) t
Uncertainty Analysis for Optimum Plane Extraction from Noisy 3D Range-Sensor Point-Clouds (Pathak et al. 2009) t
Revisiting Uncertainty Analysis for Optimum Plane Extraction from Noisy 3D Range-Sensor Point-Clouds (Pathak et al. 2009) t
- Earlier three works are concerned about the theoretical and practical aspects of extracting planes, corresponding them, and using this for pose estimation
- The last work is important to mine because it is about making a mesh representation with the planes

Continuous Localization Using Evidence Grids (1998)
Mobile Robot Exploration and Map-Building with Continuous Localization (1998)
- Navy Center for Applied Research in Artificial Intelligence - Alan Schultz, William Adams

A system for volumetric robotic mapping of abandoned mines (2003)
Learning compact 3D models of indoor and outdoor environments with a mobile robot (2003)
Robotic mapping: A survey (2003)
FastSLAM: A Factored Solution to the Simultaneous Localization and Mapping Problem (2002)
Robust Monte Carlo localization for mobile robots
Using em to learn 3d models of indoor environments with mobile robots (2001)
A real-time algorithm for mobile robot mapping with applications to multi-robot and 3D mapping (2000)
A probabilistic approach to concurrent mapping and localization for mobile robots (1998)
- Carnegie Mellon - Sebastian Thrun
- Wolfram Burgard - University of Freiburg

Unified Inverse Depth Parametrization for Monocular SLAM (2006)
Mapping large loops with a single hand-held camera (2007)
Inverse Depth Parametrization for Monocular SLAM (2008)
On the use of inverse scaling in monocular SLAM (2009)
- Universidad de Zaragoza, Spain - J. Montiel, Javier Civera
- College of London - Andrew Davidson
- Sensor: Single Camera; Representation: Sparse 3D Map; Method: EKF
- They describe a reparametrization of features in monocular SLAM applications. 
- Their parametrization is supposed to naturally encode the inverse of the depth into to the feature.
- They claim this method allows the uncertainties of every feature to be Gaussian which is much better for EKF
- The key insight of their work is that features come in from infinity. When first initialized the homogenous coordinate describes the point at infinity and as succesive measurments are made the feature is updated

Highly scalable appearance-only SLAM-FAB-MAP 2.0 (2008)
FAB-MAP: probabilistic localization and mapping in the space of appearance (2008)
Accelerated appearance-only SLAM (2008)
Probabilistic appearance based navigation and loop closing (2007)

On the Development of a Robust, Fast and Lightweight Keypoint Descriptor
{ UFMG - Erickson Nascimento, Gabriel Leivas, Antonio Wilson, Mario Campos }
- name of novel descriptors is BRAND and BASE
- BRAND is computationally more expensive but more robust with respect to scale and rotation invariance 
- True novelty of this work is to efficiently 

fast projective data association algorithm
Registering multiview range data to create 3D computer objects (1995)

point plane metric
Object modeling by registration of multiple range images (1992)

first real time implementation of using the fast projective data association algorithm with the point plane metric
Real-time 3D model acquisition 2002

